<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>About Me - Sravani Pati</title>
  <link rel="stylesheet" href="master.css">
</head>
<body>
  <!-- Navigation Bar -->
  <div class="about__nav">
    <div class="width-33 logo">Port <span class="span-col">folio</span></div>
    <a href="about.html"><span class="span-col">About</span></a>
    <a href="education.html">Education</a>
    <a href="Skills.html">My Skills</a>
    <a href="Experience.html">Experience</a>
    <a href="Projects1.html">Projects</a>
    <a href="certificates.html">Certificates</a>
    <a href="testimonal.html">Testimonial</a>
    <a href="index.html">Home</a>
  </div>

  <!-- ABOUT SECTION -->
  <div class="main-section">
    <!-- Profile Image -->
    <div class="profile-image">
      <img src="Newimage.jpg" alt="Profile Picture of Sravani Pati">
    </div>

    <article class="content__about">
      <h1 class="heading-text">About Me</h1>
      
      <p>
        Hello! I’m Sravani Pati, a passionate data enthusiast with a creative edge and a relentless drive to excel in AI and data science. My journey is fueled by a love for technology and a dedication to harnessing data to create meaningful, impactful solutions. With a strong foundation in machine learning, statistical analysis, and data engineering, I am committed to leveraging my skills to solve real-world challenges. Known for my analytical rigor and ability to innovate, I am eager to bring my expertise to an organization where I can contribute significantly while continuing to grow as a data science professional.
    </p>
    
    <h2 class="section-title">Bachelors Journey (2017 - 2021)</h2>
     <p>
        Inspired by my early fascination with technology, I pursued a Bachelor’s degree in Computer Science from Sampoorna Institute of Technology and Research, Visvesvaraya Technological University. Throughout my studies, I consistently achieved a GPA above 8.5 each semester, culminating in an impressive overall GPA of 8.9/10. This accomplishment stands as a testament to my dedication and perseverance, earning me recognition among faculty and peers alike. By my final semesters, I ranked among the top 10 in the university, a proud moment that brought honor to my professors and family.
    </p>
<br>
      <!-- Achievement Banner Section -->
<div class="achievement-banner">
  <img src="ban.jpg" alt="Sravani Pati's Achievement Banner for Top 6th Rank in University">
  <p class="caption">Honored by Sampoorna Group of Institutions for securing the 6th University Rank in B.E (CSE), VTU.</p>

</div>

<div class="custom-image-gallery">
  <img src="faculty.jpg" alt="Sravani Pati's Achievement Banner for Top 6th Rank in University" class="custom-gallery-image">
  <img src="princi.jpg" alt="Sravani Pati's Achievement Banner for Top 6th Rank in University" class="custom-gallery-image">
  <img src="ethnic.jpg" alt="Sravani Pati's Achievement Banner for Top 6th Rank in University" class="custom-gallery-image">
</div>

<a href="https://www.sampoornainstitutions.org/" class="custom-college-link" target="_blank">
  Visit: Sampoorna Institute of Technology and Research (VTU)
</a>



<div class="main-section">
  <h2 class="section-title">Key Projects and Experiences</h2>

  <!-- Experience 1: University Admission Prediction System -->
  <article class="experience">
    <h3>Machine learning specialist ( Internship 2019 )</h3>
    <p><strong>Internship at Aptech | Duration: 3 months</strong></p>
    <p>
      Driven by a passion for applying data science to real-world challenges, I gained practical experience during an internship with Aptech, where I developed a machine learning model for a <strong>University Admission Prediction System</strong>. This project encompassed end-to-end data processing, model training, and evaluation. After testing multiple algorithms, I identified the <strong>Multi-layer Perceptron</strong> as the most effective model and deployed it on a website, enabling students to input their profiles and receive tailored college recommendations based on their likelihood of admission. This experience not only deepened my technical skills in machine learning and deployment but also showed me firsthand how AI can drive personalized, impactful solutions.
    </p>
    <ul>
      <li>Improved prediction accuracy by <strong>35%</strong> with model optimization.</li>
      <li>Utilized AWS EC2 for model deployment and AWS S3 for data storage.</li>
      <li>Integrated AWS Lambda to reduce processing time and costs, improving efficiency by <strong>20%</strong>.</li>
      <li>Streamlined API handling through integration with Amazon API Gateway, reducing shortlisting time by <strong>70%</strong>.</li>
    </ul>
    <a href="Experience.html" class="view-more-link">View More Details</a>

  </article>
<br>

<article class="experience">
  <h3> Machine learning and Python (2020 - 2021)</h3>
  <p><strong>Final Year Project | Duration: 2020 - 2021</strong></p>
  <h4>Object Detection in Real-Time with Voice Output</h4>
  
  <p>
      In my final year, I developed a real-time object detection system using YOLO and pyttsx3 for voice output. This system assists visually impaired individuals by identifying and naming objects in their path, providing them with vital spatial awareness. It detects multiple objects in various environments and delivers audio messages to notify the user of any detected objects.
  </p>

  <ul>
      <li><strong>Adversarial Attacks</strong>: Explored techniques such as hiding attacks and misclassification attacks to test the robustness of the object detection system.</li>
      <li><strong>Voice Output</strong>: Integrated text-to-speech functionality using pyttsx3, enabling detected objects to be announced audibly.</li>
      <li><strong>YOLO Algorithm</strong>: Implemented the YOLO (You Only Look Once) object detection model, which offers high-speed processing with reliable accuracy.</li>
      <li><strong>Real-Time Detection</strong>: Achieved a detection accuracy of over 95% with real-time processing, providing quick responses for user safety.</li>
  </ul>

  <p>
      This project not only strengthened my technical knowledge but also inspired me deeply. The experience of creating a solution with real-world impact motivated me to pursue a master’s degree, with a vision to advance my career in data science and AI.
  </p>

  <!-- Link to Detailed Project Section -->
  <a href="Object.html" class="view-more-link">View More Details</a>
</article>
<br>

  <!-- Experience 2: Data Scientist at Nice Hi-Tech Centre -->
  
    <h2 class="section-title">Nice Hi-Tech Centre (Full-Time Aug 2021 – Jul 2022)</h2>
    <article class="experience">
      <h3>Data Scientist | Duration: 1 year</h3>
      <p>
        After completing my bachelor’s degree, I initially planned to pursue a master’s program, but due to COVID-19, I decided to gain hands-on experience and joined <strong>Nice Hi-Tech Centre</strong> as a Data Scientist. In this dynamic startup environment, I tackled the <strong>Enron Fraud Detection Project</strong>, where I built robust data pipelines, performed feature engineering, and implemented machine learning models for fraud detection. Testing multiple algorithms, the <strong>AdaBoost model</strong> emerged as the most effective, achieving an accuracy of <strong>81.29%</strong> and showcasing my commitment to precision and reliability in threat detection.
      </p>
      <ul>
        <li>Deployed fraud detection models on Microsoft Azure using Pyspark and SQL for data management.</li>
        <li>Reduced inconsistencies by <strong>95%</strong> through effective feature engineering.</li>
        <li>Enhanced model performance by <strong>20%</strong> with hyperparameter tuning using GridSearchCV.</li>
        <li>Streamlined workflows with CI/CD pipelines, lowering hosting costs by <strong>60%</strong>.</li>
      </ul>
      <a href="Experience.html" class="view-more-link">View More Details</a>
    </article>
 
  



      <h2 class="section-title">Masters Journey (2022 - 2024)</h2>
      <p>
        In August 2022, my dream came true as I joined Clemson University, one of the top 100 universities in the USA. The decision to choose Clemson was driven by its cutting-edge resources, including world-class supercomputing facilities and an inspiring research environment. Clemson’s commitment to innovation, hands-on labs, and real-world applications offered the ideal setting for me to advance in data science.
    </p>
    
    <!-- Image Gallery Section -->
    
    
  <div class="full-width-image">
    <img src="WhatsApp Image 2024-11-07 at 12.50.24 AM.jpeg" alt="Clemson University Sign">
</div>

<div class="image-gallery">
  <img src="2024.jpeg" alt="Supercomputing Facility at Clemson" class="gallery-image">

   <img src="WhatsApp Image 2024-11-06 at 10.19.32 PM.jpeg" alt="Supercomputing Facility at Clemson" class="gallery-image">
  
</div>

<div class="image-gallery">
  <img src="Gradimage.jpeg" alt="Research Lab at Clemson" class="gallery-image">
  <img src="Library.jpeg" alt="Clemson University Campus" class="gallery-image">
</div> 

  <div class="image-gallery">
   <img src="WhatsApp Image 2024-11-06 at 10.19.35 PM.jpeg" alt="Clemson University Campus" class="gallery-image">
   <img src="WhatsApp Image 2024-11-07 at 12.50.24 AM (1).jpeg" alt="Supercomputing Facility at Clemson" class="gallery-image">
  
   
</div>

    <p>
        During my time here, I have immersed myself in various real-time projects and gained hands-on experience with trending technologies across multiple domains. I completed my Master’s in Data Science with a commendable GPA of 3.8, which stands as a testament to my hard work and dedication. Through Clemson, I acquired a wealth of skills, ranging from advanced data analytics to machine learning and AI, equipping me to tackle complex challenges in the field – just as I had dreamed.
    </p>
    
<a href="https://www.clemson.edu/index.html" class="college-link" target="_blank">Visit : Clemson University</a>



  <h2 class="section-title">Key Projects and Experiences</h2>

  <!-- Project 2022: Real-Time Knowledge Acquisition -->
  <article class="experience">
    <h3>Real-Time Knowledge Acquisition (Aug 2022 - Dec 2022)</h3>
    <p><strong>Human-Centered Computing Project | Duration: 5 months</strong></p>
    <p>
      As part of my Human-Centered Computing class, I developed a <strong>Real-Time Knowledge Acquisition</strong> system, designed as a College Information Management System to support efficient data management and real-time updates for students, faculty, and administrators. This project honed my skills in full-stack development, with a focus on human-centered design principles that prioritize usability and accessibility for all users.
    </p>
    <ul>
      <li>Built with <strong>Django</strong> for backend and <strong>Bootstrap</strong> for a responsive front-end.</li>
      <li>Enabled real-time data access for attendance, grades, and schedules.</li>
      <li>Conducted usability testing to ensure the system met user needs and minimized data inaccuracies.</li>
    </ul>
    
    <!-- Link to Detailed Project Section -->
    <a href="RTKA.html" class="view-more-link">View More Details</a>
  </article>

<br>
<!-- Project 2022: Adversarial Attacks Against Object Detection -->
<article class="experience">
  <h3>Adversarial Attacks Against Object Detection (Aug 2022 - Dec 2022)</h3>
  <p><strong>Research Project in Security and Computing Principles | Instructor: Prof. Mert Pese | Duration: 5 months </strong></p>
  <p>
    As someone deeply passionate about machine learning, I had the opportunity to build on my prior experience from my bachelor’s project, expanding it from a machine learning perspective to a security-focused application. In this project for the <strong>Security and Computing Principles</strong> course, I explored adversarial attack methods on object detection models, studying the vulnerabilities of classifiers and ways to mitigate these risks.
  </p>
  <p>
    Under the guidance of <strong>Professor Mert Pese</strong>, a highly knowledgeable and inspiring educator in the field of security, I delved into attack strategies like <strong>Hiding Attack (HA)</strong> and <strong>Misclassification Attack (MA)</strong>. This research not only enhanced my understanding of machine learning but also gave me insights into real-world security challenges and defense strategies.
  </p>
  <ul>
    <li>Developed robust adversarial examples (AEs) using <strong>Feature-Interference Reinforcement (FIR)</strong> and realistic constraints.</li>
    <li>Achieved a 90% success rate in evading detection across multiple object detection models such as YOLO and RCNN.</li>
    <li>Demonstrated transferability of attacks across models, with extensive testing in varied physical environments.</li>
  </ul>
  
  <!-- Link to Detailed Project Section -->
  <a href="Attacks.html" class="view-more-link">View More Details</a>
</article>

<br>
<!-- Project: Data Breaches in Top Tech Companies -->
<article class="experience">
  <h3>Data Breaches in Top Tech Companies (Aug 2022 - Dec 2023)</h3>
  <p><strong>Major Project in Data Visualization | Instructor: Prof. Federico Iuricich | Duration: 5 months</strong></p>
  <p>
    This project focused on creating insightful visualizations of data breaches among top tech companies using techniques like bubble charts, bar charts, and donut charts. Under the expert guidance of <strong>Professor Federico Iuricich</strong>, who possesses deep expertise in data visualization, I had the privilege to enhance my skills in data storytelling with tools like <strong>Tableau</strong> and <strong>D3.js</strong>. This project highlighted sensitive data vulnerabilities exploited through hacking techniques, including email, SSN, and personal information, across different companies.
  </p>
  <ul>
    <li>Developed interactive bubble charts representing data losses across various sensitivity types.</li>
    <li>Utilized bar charts to compare data losses per company, scaled in millions for clarity.</li>
    <li>Created a donut chart to analyze hacking techniques used across compromised companies, adding hover and filter interactions for enhanced user experience.</li>
    <li>Implemented year-based data filtering and dynamic updates across visualizations, linking charts to allow synchronized data views for comprehensive analysis.</li>
  </ul>

  <!-- Link to Detailed Project Section -->
  <a href="DataBreaches.html" class="view-more-link">View More Details</a>
</article>

<br>
<!-- Project: Migraine Classification Based on Gene Expressions -->
<article class="experience">
  <h3>Migraine Classification Based on Gene Expressions (Jan 2023 - May 2023)</h3>
  <p><strong>Applied Data Science Project | Instructor: Prof. Carlos Toxtli | Duration: 5 months </strong></p>
  <p>
    This project aimed to classify types of migraines using gene expression data through advanced machine learning models. Under the expert guidance of <strong>Professor Carlos Toxtli</strong>, an inspiring educator with deep knowledge in AI, I was able to explore various models like K-Nearest Neighbor (KNN), Decision Tree, Multi-Layer Perceptron (MLP), Support Vector Machines (SVM), Random Forest, and XGBoost. This hands-on experience enhanced my understanding of data preprocessing, model evaluation, and optimization techniques.
  </p>
  <ul>
    <li>Data Collection: Analyzed blood samples and RNA sequences from patients, identifying key genetic markers for migraines.</li>
    <li>Data Preprocessing: Converted gene sequences to numeric quality scores, implemented feature engineering, and handled outliers.</li>
    <li>Model Evaluation: Applied multiple models, achieving the highest accuracy (93%) with the Random Forest model for classifying migraine types.</li>
    <li>Feature Importance Analysis: Identified influential genes and quality scores critical to migraine classification.</li>
  </ul>
  <p>
    The project concluded with the successful application of Random Forest, demonstrating a high prediction accuracy for migraine type classification. These findings underscore the potential of machine learning in medical diagnostics, potentially guiding targeted treatments for migraine sufferers.
  </p>

  <!-- Link to Detailed Project Section -->
  <a href="Migraine.html" class="view-more-link">View More Details</a>
</article>

<br>
<!-- Deep Learning Projects Section -->

  <!-- Project 1: GAN Architectures for Image Generation -->
  
  <br>

  <!-- Project 2: Simulating and Visualizing the Optimization Process -->
  <article class="experience">
    <h3>Simulating and Visualizing the Optimization Process (Jan 2023 - Feb 2023)</h3>
    <p><strong>Project in Deep Learning Optimization | Instructor: Prof. Feng Luo </strong></p>
    <p>
      This project explores various aspects of neural network optimization using the MNIST dataset. It involved visualizing optimization processes through PCA, observing gradient norms and loss across epochs, and examining overfitting behavior in CNN models. Key experiments included studying the effects of network parameter scaling on generalization, analyzing optimization landscape flatness, and comparing performance across different batch sizes and learning rates. 
    </p>
    <ul>
      <li>Used PCA to visualize optimization dynamics on a 3-layer model and analyzed model response to random labels.</li>
      <li>Investigated the impact of increasing parameters on overfitting and generalization.</li>
      <li>Analyzed optimization landscape characteristics by varying batch sizes and learning rates, providing insights into network performance.</li>
    </ul>
    <a href="https://github.com/sravani919/Deep-Learning-8430-HW1" class="view-more-link" target="_blank">View the Code on GitHub</a>
  </article>
  <br>

  <!-- Project 3: Extractive Question Answering with BERT on Spoken Language -->
  <article class="experience">
    <h3>Extractive Question Answering Model Using BERT on Spoken Language (Jan 2023 - May 2023)</h3>
    <p><strong>Deep Learning Project in NLP | Instructor: Prof. Feng Luo </strong></p>
    <p>
      Developed an extractive question-answering model for spoken language processing using the <strong>SpokenSquad dataset</strong> and <strong>BERT</strong>. This project addressed challenges like noise and errors in spoken data, employing BERT's advanced training methods, such as Masked Language Modeling and Next Sentence Prediction. By fine-tuning pre-trained models from Hugging Face, the model achieved notable accuracy, as evaluated by F1 scores, and optimized the learning rate using a linear scheduler. The 'doc stride' parameter was particularly useful for handling sequential text passages.
    </p>
    <ul>
      <li>Adapted BERT for spoken language question-answering, focusing on handling noise and improving response accuracy.</li>
      <li>Optimized model performance with learning rate scheduling and implemented strategies to handle large text passages.</li>
      <li>Evaluated model with precision-focused metrics (F1 score) to assess accuracy in spoken language processing.</li>
    </ul>
      <a href="https://github.com/sravani919/DeepLearning-Hw3_SravaniPati" class="view-more-link" target="_blank">View the Code on GitHub</a>
  
  </article>
<br>
  <article class="experience">
    <h3>Exploring Advanced GAN Architectures for Image Generation (Apr 2023)</h3>
    <p><strong>Project in Advanced Deep Learning | Instructor: Prof. Feng Luo </strong></p>
    <p>
      This project investigates three advanced GAN architectures: <strong>DCGAN</strong> (Deep Convolutional GANs), <strong>WGAN</strong> (Wasserstein GANs), and <strong>ACGAN</strong> (Auxiliary Classifier GANs). The focus was on evaluating each model's capabilities for high-quality image generation on the CIFAR-10 dataset. Key aspects include DCGAN's use of convolutional layers and batch normalization for realistic images, WGAN's innovative Wasserstein loss function to improve training stability, and ACGAN's integration of attribute-specific classifiers for targeted image generation.
    </p>
    <ul>
      <li>Applied each GAN architecture to generate distinct, high-quality images.</li>
      <li>Explored the strengths and limitations of each model, especially in handling training instability and feature-specific generation.</li>
      <li>Implemented and evaluated models on the CIFAR-10 dataset, gaining insights into the practical applications of GANs in image synthesis.</li>
    </ul>
    <a href="https://github.com/sravani919/Spati_HW4_Deep_Learning" class="view-more-link" target="_blank">View the Code on GitHub</a>
  </article>


    



<!-- Data Scientist and Data Analyst Role at Clemson Engineers for Developing Communities -->

  <h2 class="section-title"> Clemson Engineers for Developing Communities (CPT Aug 2023 - May 2024
  )
  </h2>
  <p>
    I have always been passionate about serving communities and helping people. Fortunately, during my third semester, I had the opportunity to work with Clemson Engineers for Developing Communities (CEDC) as part of my CPT. This experience allowed me to contribute to underserved communities, and I felt a deep sense of fulfillment in being part of CEDC. Initially, I joined as a Data Analyst, and soon, due to my performance, I was also given the role of Data Scientist. In this role, I worked with real data to manage disaster analysis and grant automation.
</p>
<div class="achievement-banner">
  <img src="self.jpg" alt="Sravani Pati's Achievement Banner for Top 6th Rank in University">

</div>
<p>
    I am grateful to my manager, Victoriana Malvaso, who guided me through the grant automation project with great expertise, and to Rieta Drinkwine, who supported me in my Data Analyst role with her remarkable leadership and understanding. Recognizing my capabilities, Rieta promoted me to Team Leader, where I managed a diverse team of four individuals who were new to data analysis tools. I provided them with guidance on tool functionality, outlined code structures, and developed templates to streamline the analysis process. I created templates and reusable code structures so they could easily change file names and perform analysis across multiple files. To ensure everyone’s understanding, I occasionally held one-on-one sessions, giving them hands-on support and detailed explanations.
</p>
<p>
    Both Rieta and Victoriana were incredibly supportive, and I learned a lot from them. I am also thankful to David for providing me with this opportunity to serve communities. This phase of my career taught me invaluable lessons, and I am honored to have been part of this impactful journey.
</p>
  <!-- DSR3P Fund Navigator Project -->
  <article class="experience">
    <h3>Data Scientist - DSR3P Fund Navigator Project | Duration: 10 Months </h3>
    <p><strong>Associated with Clemson Engineers for Developing Communities</strong></p>
    <p>
      During my tenure as a Data Scientist for the DSR3P Fund Navigator project, I developed and implemented advanced machine learning models to automate the categorization of federal grants. This project aimed to simplify the grant application process for low-capacity communities, enabling streamlined grant identification and supporting equitable resource allocation. My key contributions included:
    </p>
    
    <ul>
      <li><strong>Data Preprocessing and Cleaning</strong>: Launched a robust data preprocessing pipeline using Microsoft Azure, reducing data inconsistencies by 95% through automated validation scripts.</li>
      <li><strong>Natural Language Processing (NLP)</strong>: Employed tokenization, stop-word removal, and LDA topic modeling to uncover themes in grant descriptions, supporting targeted grant recommendations.</li>
      <li><strong>Machine Learning Model Development</strong>: Trained various machine learning models, achieving high accuracy with Logistic Regression and Multinomial Naive Bayes. Applied techniques like SMOTE to handle class imbalance.</li>
      <li><strong>Feature Engineering and Model Refinement</strong>: Incorporated bi-grams and tri-grams, conducted error analysis, and improved model performance iteratively.</li>
      <li><strong>Interactive Dashboards and Data Insights</strong>: Developed Tableau dashboards for strategic insights, enhancing decision-making by 30% and using SQL databases for efficient data management.</li>
      <li><strong>Grant Classification</strong>: Successfully classified over 7000 grants for future automation, paving the way for streamlined processes.</li>
      <li><strong>Future Work and Deployment</strong>: Focused on creating an intuitive user interface, integrating models into operational systems, and establishing feedback mechanisms for continuous improvement.</li>
    </ul>
    <a href="Experience.html" class="view-more-link">View More Details</a>
  </article>
  <br>

  <!-- Disaster Management and Community Resilience Analysis -->
  <article class="experience">
    <h3>Data Analyst - Disaster Management and Community Resilience Analysis | Duration: 10 Months </h3>
    <p><strong>Associated with Clemson Engineers for Developing Communities</strong></p>
    <p>
      In my role as a Data Analyst, I led a project that combined Python and Power BI to analyze qualitative data from disaster preparedness and recovery interviews. This project aimed to uncover community resilience patterns and support policy-making. Key contributions included:
    </p>
    <ul>
      <li><strong>Python Analysis</strong>: Conducted text preprocessing, term frequency analysis, and topic modeling in Python, uncovering key themes in disaster resilience discussions.</li>
      <li><strong>Power BI Visualization</strong>: Used Power BI for spatial analysis, generating interactive dashboards to visualize regional variations in disaster experiences.</li>
      <li><strong>Key Findings</strong>: Revealed themes like community engagement, infrastructure challenges, and natural disaster impacts through comprehensive topic modeling and geographic analysis.</li>
      <li><strong>Integration with Power BI</strong>: Leveraged Power BI's geographic visualization to map disaster-related themes, enhancing the accessibility of insights for stakeholders.</li>
      <li><strong>Role and Contributions</strong>: Supervised a team of four, conducted KT analysis for tool selection, provided training in Python, Power BI, and Tableau, and led data cleaning strategies to ensure high analysis accuracy.</li>
    </ul>
    <a href="Experience.html" class="view-more-link">View More Details</a>
 </article>
  <br>

  <!-- Cross-functional Team Collaboration -->
  <article class="experience">
    <h3>Cross-functional Collaboration and Leadership</h3>
    <p>
      Collaborating with cross-functional teams, I contributed to developing the Fund Navigator tool using Scrum methodology and QA testing. Leveraging machine learning and NLP techniques, I optimized grant allocation strategies by 45%, achieving 91.67% accuracy and supporting automated decision-making.
    </p>
    <ul>
      <li><strong>Grant Allocation Optimization</strong>: Enhanced allocation strategies with Multinomial Naive Bayes and NLP, resulting in a 45% improvement and 91.67% accuracy in decision-making processes.</li>
      <li><strong>Web Scraping for Data Collection</strong>: Used Python’s BeautifulSoup and Selenium to gather grant data from government sites, boosting data pipeline throughput by 35%.</li>
      <li><strong>Training and Support</strong>: Supervised a team of four, providing training in Power BI, Tableau, and Python, streamlining project processes by 80%.</li>
      <li><strong>Tool Evaluation</strong>: Conducted Kepner-Tregoe analysis and A/B testing to evaluate tools, improving testing efficiency by 65%.</li>
    </ul>
    
<br>
<br>
    <div class="cedc-gallery">
      <div class="cedc-row">
      <img src="cedcfinal.jpg" alt="Picture 1 at CEDC Internship" class="cedc-gallery-image">
      <img src="cedcgroup.jpg" alt="Picture 2 at CEDC Internship" class="cedc-gallery-image">
      <img src="cedcengagement.jpg" alt="Picture 3 at CEDC Internship" class="cedc-gallery-image">
     
    </div>
    <div class="cedc-row">
       <img src="cedcsocioeconomic.jpg" alt="Picture 4 at CEDC Internship" class="cedc-gallery-image">
  
      <img src="davidcedc.jpg" alt="Picture 5 at CEDC Internship" class="cedc-gallery-image">
      <img src="cedcgang.jpg" alt="Picture 6 at CEDC Internship" class="cedc-gallery-image">
    </div>
      <!-- Add more images as needed -->
  </div>
  <p class="cedc-gallery-caption">CEDC Photo Gallery</p>

    <a href="https://cecas.clemson.edu/cedc/" class="college-link" target="_blank">Visit : Clemson Engineers for developing communities </a>


  </article>
  


<article class="experience">
  <h3>Failure Point Automation (Aug 2023 - Dec 2023)</h3>
  <p><strong>Project in Critical Infrastructure Automation | Instructor: Prof. David Vaughn | Duration: 5 months</strong></p>
  <p>
    This project integrated machine learning with GIS to automate the analysis of critical infrastructure risks, enhancing disaster resilience in underserved communities. Under the guidance of <strong>Professor David Vaughn</strong>, I developed and implemented advanced computer vision algorithms such as CNN and R-CNN. This proof-of-concept project aims to improve community resilience by automating the identification of critical infrastructure failure points along the Savannah River Watershed.
  </p>
  <ul>
    <li>Selected and trained a Convolutional Neural Network (CNN) model for image classification, with future scalability to Region-based CNN (R-CNN) for object recognition.</li>
    <li>Manually collected and preprocessed satellite images of critical infrastructure (e.g., substations, broadband towers) using ArcGIS and Google Earth.</li>
    <li>Applied data augmentation techniques to expand the dataset and enhance model training, improving model accuracy and robustness.</li>
    <li>Identified potential challenges and troubleshooting steps, such as refining data augmentation methods and implementing data transfer techniques to increase training sample size.</li>
  </ul>

  <p><strong>Future Steps:</strong> The next phase focuses on integrating the model with ArcGIS to automate mapping, refining CNN to R-CNN for precise failure point localization, and expanding infrastructure categories to better serve low-capacity communities across the nation.</p>

 
  <div class="cedc-gallery">
    <div class="cedc-row">
    <img src="SravaniPoster.jpg" alt="Picture 1 at CEDC Internship" class="cedc-gallery-image">
    <img src="FPAPoster.jpg.jpeg" alt="Picture 2 at CEDC Internship" class="cedc-gallery-image">
    <img src="Milestone.jpeg" alt="Picture 3 at CEDC Internship" class="cedc-gallery-image">
    <img src="Summitposter.jpg" alt="Picture 3 at CEDC Internship" class="cedc-gallery-image">
    
   
  </div>
  </div>
   <!-- Link to Detailed Project Section -->
   <a href="Failurepoints.html" class="view-more-link">View More Details</a>

</article>

<br>
<article class="experience">
  <h3>Pizza Store Database Project (Aug 2023 - Dec 2023)</h3>
  <p><strong>Project in Database Management Systems | Instructor: Prof. Connie Taylor | Duration: 5 months</strong></p>
  <p>
    This project focused on designing and implementing a comprehensive database for Pizzas-R-Us, incorporating an Enhanced ER model to manage orders, toppings, customers, and discounts. Using SQL and Java, I developed a MySQL database, created reporting views, and built a command-line application for order management and profitability analysis.
  </p>
  <ul>
    <li>Designed an Enhanced Entity-Relationship Diagram (ERD) to represent the database structure.</li>
    <li>Developed SQL scripts to create and populate tables and implemented views for insights, such as topping popularity and profit analysis.</li>
    <li>Built a Java command-line application for customer management, order processing, and inventory tracking, connected via JDBC.</li>
  </ul>
  <!-- Link to Detailed Project Section -->
  <a href="Pizza.html" class="view-more-link">View More Details</a>
</article>
<br>
<article class="experience">
  <h3>Cloud Solution Architecture for High Availability and Security (Jan 2024 - May 2024)</h3>
  <p><strong>Project in Cloud Computing | Instructor: Prof. Mitch Shue | Duration: 5 months</strong></p>
  <p>
    This project involved designing a robust cloud architecture aimed at high availability, security, and scalability using Amazon Web Services (AWS). Guided by <strong>Professor Mitch Shue</strong>, who provided comprehensive insights into cloud computing concepts, we developed skills through hands-on labs and various projects that reinforced practical knowledge in cloud environments.
  </p>
  <ul>
    <li>Built an auto-scaling architecture across multiple availability zones, integrating load balancing and scaling policies to ensure high availability.</li>
    <li>Implemented security measures including Identity and Access Management (IAM) with role-based access control to enhance cloud security.</li>
    <li>Leveraged AWS CloudWatch, CloudTrail, and AWS Config for real-time monitoring, auditing, and compliance management.</li>
    <li>Configured network and security settings with customized security groups, VPC, and NAT gateways to secure resources and manage access control.</li>
  </ul>
  <p>This project, along with additional hands-on labs, equipped me with in-depth knowledge of cloud infrastructure and security practices essential for cloud-based solutions.</p>
</article>
<br>
<article class="experience">
  <h3>Malware Analysis Project (Aug 2023 – Dec 2023)</h3>
  <p><strong>Course: Malware Reverse Engineering | Instructor: Prof. Lu Yu | Duration: 5 months </strong></p>
  <p>
    These projects focused on malware static and dynamic analysis techniques on Windows, employing tools like PEiD, VirusTotal, and IDA Pro. The analysis covered various indicators of malicious behaviors, such as persistence mechanisms, host-based signatures, and network-based indicators.
  </p>
  <ul>
    <li><strong>Static Analysis:</strong> Utilized PEiD, IDA, and VirusTotal for analyzing malware functions, imports, and potential file modifications.</li>
    <li><strong>Dynamic Analysis:</strong> Observed malware behavior using Any.Run to analyze registry modifications, file interactions, and network activities in a virtualized environment.</li>
    <li><strong>DLL Injection:</strong> Explored DLL injection techniques using C++ to simulate memory manipulation, handle acquisition, and thread injection in malware scenarios on virtualized systems.</li>
  </ul>
  <p>
    Now, I am also equipped to identify vulnerabilities and determine if a system or file contains malware, improving security and ensuring that malicious threats are effectively managed.
  </p>
</article>
<br>
<article class="experience">
  <h3>Portfolio Website Development (Feb 2024)</h3>
  <p><strong>Personal Project | Duration: 1 month</strong></p>
  <p>
    This portfolio serves as a centralized showcase of my skills, achievements, and projects in a visually engaging, user-friendly format. Crafted with HTML, CSS, and JavaScript, it highlights my journey in web development and is optimized for responsive design across devices.
  </p>
  <ul>
    <li><strong>Design & Layout:</strong> Built with a mobile-first approach, using media queries for consistent, responsive design across desktops, tablets, and mobile devices.</li>
    <li><strong>Interactive Elements:</strong> Integrated smooth scrolling, navigation, and JavaScript-based dynamic elements to enhance user engagement.</li>
    <li><strong>Project Displays:</strong> Featured project showcases with descriptions, images, and links, allowing visitors to explore my work in-depth.</li>
    <li><strong>Optimized User Experience:</strong> Organized structure with semantic HTML, accessible navigation, and clear, interactive elements for easy exploration.</li>
  </ul>
  <p>
    This project has been a valuable learning experience, from solving layout challenges with CSS media queries to implementing interactivity through JavaScript, reflecting my growth in web development. Future plans include incorporating React.js for enhanced interactivity and expanding the project showcase as my portfolio evolves.
  </p>
  <!-- Link to Detailed Portfolio Section -->
  <a href="Portfolio.html" class="view-more-link">View More Details</a>
</article>

<br>
<article class="experience">
  <h3>TikTok Claims Classification (Jan 2024 - Mar 2024)</h3>
  <p><strong>Personal Project | Duration: 3 months</strong></p>
  <p>
    This project applied the PACE (Project, Analyze, Communicate, Execute) strategy to build a machine learning model for classifying TikTok claims and opinions, aimed at enhancing content moderation and improving user experience. Through a series of six milestones, I tackled data analysis, hypothesis testing, regression modeling, and final machine learning implementation.
  </p>
  <ul>
    <li><strong>Milestone 1:</strong> Developed project proposal, defined milestones, identified stakeholders, and established PACE workflow for organized execution.</li>
    <li><strong>Milestone 2:</strong> Built and examined a data frame of TikTok’s dataset, performed initial EDA, and provided summary insights.</li>
    <li><strong>Milestone 3:</strong> Conducted comprehensive EDA with visualizations, exploring key variables and correlations in claims versus opinion data.</li>
    <li><strong>Milestone 4:</strong> Performed hypothesis testing to compare video engagement across user types, yielding insights into verified vs. unverified account behavior.</li>
    <li><strong>Milestone 5:</strong> Built a logistic regression model to analyze verified vs. unverified account attributes, achieving notable predictive accuracy.</li>
    <li><strong>Milestone 6:</strong> Developed and fine-tuned a Random Forest classification model, achieving a recall score of 99.5%, with feature importance highlighting user engagement metrics.</li>
  </ul>
  <p>
    The final model identified claims effectively, minimizing false negatives to ensure TikTok’s human moderators focus on content most likely to violate terms of service. This project sharpened my skills in EDA, hypothesis testing, and machine learning model tuning, and reinforced the importance of ethical considerations in content moderation automation.
  </p>
  <!-- Link to Detailed Project Section -->
  <a href="Tiktok.html" class="view-more-link">View More Details</a>
</article>

<br>
<article class="experience">
  <h3>Executive Sales Analysis (Apr 2024 - Jun 2024)</h3>
  <p><strong>Personal Project | Duration: 3 Months</strong></p>
  <p>
    In this project, I prepared and configured sales data for in-depth analysis, developed a robust data model, configured advanced aggregations using DAX, and created comprehensive sales and profit reports. The project culminated in the development of an executive dashboard, complete with automated alerts and subscriptions for continuous monitoring.
  </p>
  <ul>
    <strong>Milestone 1: Data Preparation and Model Development</strong>
      <ul>
        <li>Processed raw sales data by calculating critical metrics, including Gross Revenue, Total Tax, and Net Revenue.</li>
        <li>Loaded, transformed, and optimized data within Power BI, setting appropriate data types and establishing table relationships for a structured model.</li>
        <li>Developed a time-based Calendar table to enable advanced time intelligence functions.</li>
      </ul>
   
    <strong>Milestone 2: Configure Aggregations and Create Reports</strong>
      <ul>
        <li>Created Yearly, Quarterly, and Year-to-Date profit metrics using DAX to enhance financial insights.</li>
        <li>Generated visual reports with bar, column, pie, and line charts, utilizing Power BI’s Performance Analyzer for report optimization.</li>
      </ul>
  
    <strong>Milestone 3: Dashboard Creation and Alert Configuration</strong>
      <ul>
        <li>Developed an executive dashboard by pinning key metrics and visuals from the Sales and Profit Overview reports.</li>
        <li>Configured automated alerts for essential metrics like Gross Revenue and established report subscriptions for real-time updates.</li>
      </ul>
    
  </ul>
  <p>
    This project provided hands-on experience with data modeling, DAX-driven aggregations, report design, and the configuration of an executive dashboard in Power BI, fostering data-driven decision-making through automated insights.
  </p>
  <!-- Link to Detailed Project Section -->
  <a href="executivesales.html" class="view-more-link">View More Details</a>
</article>
<br>
<div class="project-gallery">
  
  <h2>Project Gallery</h2>
  <br>
  <br>
  <div class="project-container">
    
    <a href="executivesales.html" class="project-item">
      <img src="executivesales.webp" alt="Executive Sales">
      <div class="project-overlay">
        <p>Executive Sales (2024)</p>
      </div>
    </a>
    
    <a href="Tiktok.html" class="project-item">
      <img src="Tiktok.jpg" alt="TikTok Classification">
      <div class="project-overlay">
        <p>TikTok Classification (2024)</p>
      </div>
    </a>
    
    <a href="Admission.html" class="project-item">
      <img src="Graduateadmission.jpg" alt="Graduate Prediction">
      <div class="project-overlay">
        <p>Graduate Prediction (2024)</p>
      </div>
    </a>
    
    <a href="Portfolio.html" class="project-item">
      <img src="web-developer-portfolio.webp" alt="Portfolio">
      <div class="project-overlay">
        <p>Portfolio (2024)</p>
      </div>
    </a>
    
    <a href="Failurepoints.html" class="project-item">
      <img src="Failurepoints.jpg" alt="Failure Automation">
      <div class="project-overlay">
        <p>Failure Automation (2023)</p>
      </div>
    </a>
    
    <a href="Pizza.html" class="project-item">
      <img src="Pizza.jpg" alt="Pizza Store">
      <div class="project-overlay">
        <p>Pizza Store (2023)</p>
      </div>
    </a>
    
    <a href="Migraine.html" class="project-item">
      <img src="Migraine.jpg" alt="Migraine Classification">
      <div class="project-overlay">
        <p>Migraine Classification (2023)</p>
      </div>
    </a>
    
    <a href="DataBreaches.html" class="project-item">
      <img src="Data Breaches.png" alt="Data Breaches">
      <div class="project-overlay">
        <p>Data Breaches (2022)</p>
      </div>
    </a>
    
    <a href="Attacks.html" class="project-item">
      <img src="security.jpg" alt="Adversarial Attacks">
      <div class="project-overlay">
        <p>Adversarial Attacks (2022)</p>
      </div>
    </a>
    
    <a href="RTKA.html" class="project-item">
      <img src="Realtimeknowledge.png" alt="Knowledge Acquisition">
      <div class="project-overlay">
        <p>Knowledge Acquisition (2022)</p>
      </div>
    </a>
    
    <a href="Graduate.html" class="project-item">
      <img src="GraduateAdmission.png" alt="Graduate Admission">
      <div class="project-overlay">
        <p>Graduate Admission (2021)</p>
      </div>
    </a>
    
    <a href="Object.html" class="project-item">
      <img src="Screenshot 2024-01-29 175904.png" alt="Object Detection">
      <div class="project-overlay">
        <p>Object Detection (2021)</p>
      </div>
    </a>
  </div>
</div>

<!-- AI Engineer/Researcher at Human AI Empowerment Lab, Clemson University -->

  <h2 class="section-title"> Human AI Empowerment Lab, Clemson University ( Full Time May 2024 – Present) </h2>
  <article class="experience">
    
  <h3>AI Engineer/Researcher | Duration: Present </h3>
  <p>
    Joining Clemson’s Human AI Empowerment Lab under the guidance of Assistant Professor Carlos Toxtli, a seasoned expert in AI and data science, has been a transformative experience. I developed an advanced comment triage system powered by GEMMA-2B and Gemini 1.5 Pro, achieving a 25% increase in feedback classification accuracy, reduced training time by 55% with Clemson's supercomputing resources, and engineered a data pipeline with a 95% F1-score in few-shot learning scenarios.
  </p>
  <ul>
    <li><strong>Reduced manual triage time by 50%</strong>, streamlining feedback prioritization and handling high comment volumes.</li>
    <li><strong>ACM SIG Conference Paper:</strong> Co-authored a paper with Professor Toxtli on the AI-Powered Comment Triage system, now submitted to the ACM SIG Conference.</li>
  </ul>
  <p>Currently, we are pioneering a new project, <strong>Customer Journey Mapping and Sales Forecasting with Multimodal LLMs</strong>, leveraging models like FLAVA and LLaMA to integrate diverse data formats for predictive insights in e-commerce and customer retention.</p>
  <a href="Experience.html" class="view-more-link">View More Details</a>

</article>



<!-- Picture Gallery for CEDC Internship -->












      <h2 class="section-title">Certifications and Lifelong Learning</h2>
      
    
      <ul class="key-highlights">
        <li><strong>AWS Certified Solutions Architect – Associate</strong> – Enhancing my understanding of scalable cloud infrastructures.</li>
        <li><strong>IBM Data Engineering</strong> – Building foundational skills in data pipeline management and big data handling.</li>
        <li><strong>Google Advanced Data Analytics</strong> – Mastering advanced analytics techniques to draw insights from complex data.</li>
        <li><strong>Microsoft Power BI Analytics</strong> – Proficient in creating dynamic dashboards for effective data communication.</li>
        <li><strong>Engineering Responsible Conduct of Research</strong> and <strong>Group 1 Investigators Conducting Social and Behavioral Science Research (SBR)</strong> – Ensuring adherence to ethical standards in data handling.</li>
      </ul>
    
      <h2 class="section-title">Personal Passions</h2>
     
      <p>
        Outside of work, I am passionate about dance. I constantly strive to learn new dance styles, and I've performed in various events during school and college. Another special part of my life is my pet, <strong>Leo</strong>, who remains one of my favorite companions. Above all, my parents are my pillars. My father, despite his physical challenges, has always been my strongest supporter, inspiring me to pursue my dreams without limitations.
      </p>

      <h2 class="section-title">Looking Ahead: The Future in AI</h2>
      <p>
        As a continuous learner with a commitment to mastering the evolving field of AI, I am particularly drawn to exploring AI-powered personalization, real-time insights, and multimodal data integration. I am currently preparing for further certifications in advanced AI and machine learning fields to solidify my knowledge and stay updated with cutting-edge technologies.
      </p>
   
  </div>

</body>
</html>
